<type>: Munch
<init>: true
# PyTorch Lightning System.
system:
  <type>: MimickingClassification
  <init>: true
  # Model.
  model:
    <type>: get_default_deepset
    <init>: true

  # Data loaders.
  train_loader: null
  valid_loader: null
  loaders:
    <type>: get_both_default_mimicking_loaders
    <init>: true
    distribution: "uniform"
    voting_rule|utilitarian:
      <type>: get_utilitarian
      <init>: true
    voting_rule|rawlsian:
      <type>: get_rawlsian
      <init>: true
    voting_rule|egalitarian_0.5:
      <type>: get_egalitarian
      <init>: true
      penalty_lambda: 0.5
    return_graph: false

  # Optimizer.
  optimizer:
    <type>: Lookahead
    <init>: true
    optimizer:
      <type>: Adam
      <init>: false
      lr: 0.0001
    k: 5
    alpha: 0.5

  # Learning rate scheduler.
  scheduler_wrapper:
    <type>: TransformerSchedulerWrapper
    <init>: true
    get_fn:
      <type>: get_cosine_schedule_with_warmup
      <init>: false
    num_warmup_steps: 20 # in epochs
    num_training_steps: 20000

  # Loss functions.
  loss_fn:
    <type>: CrossEntropyLoss
    <init>: true
  save_checkpoint: true

# wandb experiment
logger:
  <type>: WandbLogger
  <init>: false
  project: "lte"
  entity: "byol"
  tags: ["deepsets", "icml", "social-welfare", "take-1"]

manage_checkpoint:
  <type>: manage_checkpoint
  <init>: true
  root_path: "/scratch/hdd001/home/jennybao/projects/LTE"
  experiment_name: "social-welfare"
  load_version: null


trainer:
  <type>: Trainer
  <init>: false
  max_epochs: 20000
  gradient_clip_val: 1.

# Seed.
seed: 0
