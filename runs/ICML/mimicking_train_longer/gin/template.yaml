<type>: Munch
<init>: true
# PyTorch Lightning System.
system:
  <type>: MimickingClassification
  <init>: true
  # Model.
  model:
    <type>: get_default_gin
    <init>: true

  # Data loaders.
  train_loader: null
  valid_loader: null
  loaders:
    <type>: get_both_default_mimicking_loaders
    <init>: true
    distribution: "uniform"
#    voting_rule|plurality:
#      <type>: get_plurality
#      <init>: true
    voting_rule|borda:
      <type>: get_borda
      <init>: true
#    voting_rule|copeland:
#      <type>: get_copeland
#      <init>: true
#    voting_rule|maximin:
#      <type>: get_maximin
#      <init>: true
    return_graph: true

  # Optimizer.
  optimizer:
    <type>: Adam
    <init>: false
    lr: 0.0333

  # Learning rate scheduler.
  scheduler_wrapper:
    <type>: TransformerSchedulerWrapper
    <init>: true
    get_fn:
      <type>: get_cosine_schedule_with_warmup
      <init>: false
    num_warmup_steps: 20 # in epochs
    num_training_steps: 200000

  # Loss functions.
  loss_fn:
    <type>: CrossEntropyLoss
    <init>: true
  save_checkpoint: true

# wandb experiment
logger:
  <type>: WandbLogger
  <init>: false
  project: "lte"
  entity: "byol"
  tags: ["gin", "icml", "mimic", "train-longer"]

manage_checkpoint:
  <type>: manage_checkpoint
  <init>: true
  root_path: "/scratch/hdd001/home/jennybao/projects/LTE"
  experiment_name: "mimic"
  load_version: null
  additional_path_name: "200k_epoch_cosine_with_warmup"


trainer:
  <type>: Trainer
  <init>: false
  max_epochs: 200000
  gradient_clip_val: 1.

# Seed.
seed: 0
